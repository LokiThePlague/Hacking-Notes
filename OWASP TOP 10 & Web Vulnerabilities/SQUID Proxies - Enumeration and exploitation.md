*Squid Proxy* is a GPL-licensed proxy-cache web server whose purpose is to function as a *network proxy* and also as a cache zone for storing web pages, among other things. It is a server located between the user's machine and another network (often the Internet) that acts as a protection separating the two networks and as a cache zone to speed up access to web pages or to restrict access to content.

In other words, the function of a proxy server is to centralize traffic from a local network to the outside (Internet). Only the computer that incorporates the proxy service must have an Internet connection and the rest of the computers exit through it.

However, a Squid Proxy server may be misconfigured, allowing attackers to gather information from devices to which they should not normally have access.

For example, in this type of situation, an attacker might be able to make requests to internal IP addresses by passing their queries through the Squid Proxy, thus being able to perform a port scan against certain servers located on an *internal network*.

To do this, we could simply try using browser extensions such as **FoxyProxy** or from the console using the '**curl**' command:

```bash
curl --proxy http://10.10.11.131:3128 http://<ip>:<port>
```

In the best case scenario, if the connection does not require authentication, we could perform port enumeration on specific internal servers, replacing \<port> with the desired port to be enumerated from the corresponding \<ip> server. In case authentication is required, if the attacker has the credentials, they could be specified by using the '*-u*' parameter.

All this is possible because the proxy acts as an intermediary between the *local* and the *external* network, which in part allows access to certain internal resources that would not normally be available from the outside.

However, it is important to note that access to these resources through the proxy may be restricted by security policies, authentication or other access control mechanisms. In addition, if the proxy is configured correctly, it is likely that it will not allow access to internal resources from the outside, *even if it is being passed through*.

One of the tools commonly used to enumerate ports of a particular server passing through the Squid Proxy is [spose](https://github.com/aancw/spose).

Spose is a port scanning tool specifically designed to work through Squid Proxy servers. This tool allows attackers to search for possible open services and ports on an internal network "protected" by a Squid Proxy server.

# Example

For the realization of this example we will need to download the following machine (mirror option), install it and run it as a virtual machine: [sickos](https://www.vulnhub.com/entry/sickos-11,132/).

Once the machine is turned on we can perform a scan with **arp-scan** to see the IP assigned by our router:

```bash
arp-scan -I ens33 --localnet --ignoredups
```

This particular machine does not respond if we send *ICMP* traces to it, so it is not worth pinging it.

The first thing we are going to do is run a port scan with **nmap**:

```bash
nmap -p- --open -sT --min-rate 5000 -vvv -n -Pn 192.168.50.214
```

We see that ports *22* and *3128* are open. Let's do a new scan on these two ports to launch common **nmap** scripts and see their *services* and *versions*:

```bash
nmap -sCV -p22,3128 192.168.50.214
```

We can see that port *3128* corresponds to a *SQUID Proxy*.

To be able to see the *ports* and the resources that the machine hides we have to pass *through the proxy*.

----
> We can create a new entry in **FoxyProxy** with the IP of the machine and the *SQUID Proxy* port to see it through the browser.
----

With the **curl** tool we can access the machine through the *proxy*:

```bash
curl http://192.168.50.214 --proxy http://192.168.50.214:3128
```

Likewise with **gobuster** we can list directories through the *proxy*:

```bash
gobuster dir -u http://192.168.50.214 --proxy http://192.168.50.214:3128 -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -t 20
```

To enumerate all internal *active ports* passing through the *proxy* we can create a **Python** script:

```python
#!/usr/bin/python3

import requests
import sys
import signal

from pwn import *

def def_handler(sig, frame):
    print("\n\n[!] Exiting...\n")
    sys.exit(1)

signal.signal(signal.SIGINT, def_handler)

# It is the same to reference localhost or the IP of the machine when we are going through the SQUID Proxy.
main_url = "http://127.0.0.1"
squid_proxy = {'http': 'http://192.168.50.214:3128'}

def portDiscovery():
    common_tcp_ports = {20, 21, 22, 23, 25, 53, 67, 68, 69, 80, 88, 110, 119, 123, 135, 137, 138, 139, 143, 161, 162, 179, 389, 443, 445, 465, 514, 515, 587, 636, 993, 995, 1080, 1433, 1434, 1723, 3306, 3389, 5060, 5222, 5223, 5900, 5901, 5984, 6379, 8080, 8443, 8888, 9200, 9300, 11211, 27017}
    
    for tcp_port in common_tcp_ports:
        r = requests.get(main_url + ':' + str(tcp_port), proxies=squid_proxy)
        
        if r.status_code != 503:
            print("\n[+] Port " + str(tcp_port) + " - OPEN")

if __name__ == '__main__':
    portDiscovery()
```

In some cases, we may need to *authenticate* to use *SQUID Proxy* to reach these internal services:

```bash
curl http://192.168.50.214 --proxy http://admin:password@192.168.50.214:3128
```